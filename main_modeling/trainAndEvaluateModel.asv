function [accuracy, precision, recall, F1_score, AUC, MCC, TSS, kappa, bestParams, Xroc_cells, Yroc_cells, Xprec_cells, Yprec_cells] = trainAndEvaluateModel(data)
    

    % Filter and preprocess the data
    idx = find(data.F1 == 0);
    data(idx, :) = [];
    data_filtered = data(ismember(data.Phenotype, {'4hit', 'noncancer'}), :);
    X = table2array(data_filtered(:, 5:end));
    y = strcmp(data_filtered.Phenotype, '4hit');
    unique_dates = unique(data_filtered.Date);

    % Initialize performance metrics
    [accuracy, precision, recall, F1_score, AUC, MCC, TSS, kappa] = deal(zeros(length(unique_dates), 1));
    [Xroc_cells, Yroc_cells, Xprec_cells, Yprec_cells] = deal(cell(length(unique_dates), 1));

    rng(42);  % For reproducibility

    % Hyperparameter options (could be function inputs)
    numTreesOptions = [5, 10, 20, 30, 40, 50, 100, 200, 300, 400, 500, 1000];
    maxNumSplitsOptions = [3, 5, 8, 10, 20, 30, 40, 50, 100];
    numVarsToSampleOptions = [4, 5, 6, 7, 8, 9, 10, 20];


    numTreesOptions = [5, 10,100];
    maxNumSplitsOptions = [3, 5,50];
    numVarsToSampleOptions = [4, 5];
    % Initialize structure for storing best parameters
    bestParams = struct('Date', {}, 'NumTrees', {}, 'MaxNumSplits', {}, 'NumVarsToSample', {}, 'BestInternalAUC', {});

    % Main loop for training and evaluation
    for i = 1:length(unique_dates)
        % External CV: Split data based on date
        test_date = unique_dates{i};
        train_indices = ~strcmp(data_filtered.Date, test_date);
        X_train = X(train_indices, :);
        y_train = y(train_indices);
        X_test = X(~train_indices, :);
        y_test = y(~train_indices);

        % Normalize the external training data (done once per external loop)
        [X_train_normalized, mu, sigma] = zscore(X_train);

        % Best hyperparameters initialization
        bestInternalAUC = 0;
        bestNumTrees = 0;
        bestMaxNumSplits = 0;
        bestNumVarsToSample = 0;

       tempInternalFoldAccuracies = zeros(length(train_dates), length(numTreesOptions) * length(maxNumSplitsOptions) * length(numVarsToSampleOptions));

       %%% number of date in the process 
        train_dates = unique(data_filtered.Date(train_indices));  

        % Hyperparameter tuning (internal cross-validation)
        for nTrees = numTreesOptions
            for maxNumSplits = maxNumSplitsOptions
                for numVarsToSample = numVarsToSampleOptions
                    internalAUC = zeros(length(unique(data_filtered.Date(train_indices))), 1);
                    internalAccuracy = zeros(length(unique(data_filtered.Date(train_indices))), 1);
                    for j = 1:length(train_dates)
                        % Internal training/validation split
                        internalTrainDate = data_filtered.Date(train_indices);
                        internalValidationDate = train_dates{j};
                        internalTrainIdx = ~strcmp(internalTrainDate, internalValidationDate);
                        internalValIdx = strcmp(internalTrainDate, internalValidationDate);

                        % Separate internal training and validation sets
                        X_internal_train = X_train(internalTrainIdx, :);
                        y_internal_train = y_train(internalTrainIdx);
                        X_internal_val = X_train(internalValIdx, :);
                        y_internal_val = y_train(internalValIdx);

                        % Normalize internal training and validation data separately
                        [X_internal_train_norm, mu_internal, sigma_internal] = zscore(X_internal_train);
                        X_internal_val_norm = bsxfun(@minus, X_internal_val, mu_internal);
                        X_internal_val_norm = bsxfun(@rdivide, X_internal_val_norm, sigma_internal);

                        % Train model on internal training data
                        t = templateTree('Reproducible', true, 'MaxNumSplits', maxNumSplits, 'NumVariablesToSample', numVarsToSample);
                        model = fitcensemble(X_internal_train_norm, y_internal_train, 'Method', 'Bag', 'NumLearningCycles', nTrees, 'Learners', t);

                        % Validate model on internal validation data
                         
                        [y_pred_val, scores] = predict(model, X_internal_val_norm);
                        [~, ~, ~, AUCValue] = perfcurve(y_internal_val, scores(:, 2), 1);
                        internalAUC(j) = AUCValue;
                        cm = confusionmat(y_internal_val, y_pred_val);
                        accuracy_internal(j) = sum(diag(cm)) / sum(cm(:));


                      [y_pred_val, ~] = predict(model, X_internal_val_norm);
                    cm = confusionmat(y_internal_val, y_pred_val);
                    internalAccuracy(j) = sum(diag(cm)) / sum(cm(:));
                    [~, ~, ~, AUCValue] = perfcurve(y_internal_val, scores(:, 2), 1);
                    internalAUC(j) = AUCValue;




                    end

                    meanInternalAUC = mean(internalAUC);
                    %accuracy = sum(diag(cm)) / sum(cm(:));

                    % Update best parameters if current model is better
                    if meanInternalAUC > bestInternalAUC
                        bestInternalAUC = meanInternalAUC;
                        bestNumTrees = nTrees;
                        bestMaxNumSplits = maxNumSplits;
                        bestNumVarsToSample = numVarsToSample;
                    end
                end
            end
        end

        % Store the best parameters for each date
        bestParams(i).Date = test_date;
        bestParams(i).NumTrees = bestNumTrees;
        bestParams(i).MaxNumSplits = bestMaxNumSplits;
        bestParams(i).NumVarsToSample = bestNumVarsToSample;
        bestParams(i).BestInternalAUC = bestInternalAUC;

        % Retrain using the best parameters on the full external training set
        t = templateTree('Reproducible', true, 'MaxNumSplits', bestMaxNumSplits, 'NumVariablesToSample', bestNumVarsToSample);
        model_external = fitcensemble(X_train_normalized, y_train, 'Method', 'Bag', 'NumLearningCycles', bestNumTrees, 'Learners', t);

        % Evaluate on the external test set
        X_test_normalized = bsxfun(@minus, X_test, mu);
        X_test_normalized = bsxfun(@rdivide, X_test_normalized, sigma);
        [y_test_pred, scores_test] = predict(model_external, X_test_normalized);

        % Calculate performance metrics
        [accuracy(i), precision(i), recall(i), F1_score(i), AUC(i), MCC(i), TSS(i), kappa(i), Xroc_cells{i}, Yroc_cells{i}, Xprec_cells{i}, Yprec_cells{i}] = ...
            calculatePerformanceMetrics(y_test, y_test_pred, scores_test(:, 2));
    end

    % Feature importance for the last trained model
    %importance_scores = predictorImportance(model_external);

    % Optional: Plot feature importance
    % figure;
    % bar(importance_scores);
    % xlabel('Feature Index');
    % ylabel('Importance Score');
    % title('Feature Importance Scores');
end

